{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e022b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import parsers\n",
    "import random\n",
    "import torch\n",
    "import re\n",
    "import xml\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "from constants import SPECIAL_TOKENS\n",
    "from config import Config\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RES_FILEPATH = 'results/best-checkpoint/test.out.json'\n",
    "TRAIN_RES_FILEPATH = 'results/best-checkpoint/train.out.json'\n",
    "CKPT_PATH = 'best-checkpoint.mdl'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_results(model_dir, res_filepath):\n",
    "    print(f'Loading results from {model_dir}')\n",
    "    saved_dict = torch.load(os.path.join(model_dir, CKPT_PATH), map_location = DEVICE)\n",
    "    config = Config.from_dict(saved_dict['config'])\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.bert_model_name)\n",
    "    tokenizer.add_tokens(SPECIAL_TOKENS)\n",
    "\n",
    "    # model = TextMappingModel(config)\n",
    "    # model.load_bert(config.bert_model_name)\n",
    "    # model.bert.resize_token_embeddings(len(tokenizer))\n",
    "    # model.load_state_dict(saved_dict['model'])\n",
    "    # model.to(DEVICE)\n",
    "    \n",
    "    # print(f'Loading dataset for {model_dir}')\n",
    "    # dataset = LPMappingDataset(\n",
    "    #     path = '../data/test.jsonl',\n",
    "    #     tokenizer = tokenizer,\n",
    "    #     max_length = config.max_length,\n",
    "    #     gpu = torch.cuda.is_available(),\n",
    "    #     enrich_ner = config.enrich_ner,\n",
    "    # )\n",
    "    # dataset.numberize()\n",
    "    # dataloader = DataLoader(dataset, batch_size = 1, shuffle = False, collate_fn = dataset.collate_fn)\n",
    "    \n",
    "    with open(os.path.join(model_dir, res_filepath)) as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    return results, config, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../output/default/20230514_151250415'\n",
    "\n",
    "results, config, tokenizer = load_results(model_dir, TEST_RES_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_convert(output, order_mapping):\n",
    "    parser = parsers.ModelOutputXMLParser(print_errors = True)\n",
    "    return parser.parse(output, order_mapping)\n",
    "\n",
    "\n",
    "def convert_to_canonical(parsed, is_gold: bool):\n",
    "    return parsers.convert_to_canonical(parsed, is_gold = is_gold)\n",
    "\n",
    "\n",
    "def print_diff(gp):\n",
    "    gold = gp['gold']\n",
    "    pred = gp['pred']\n",
    "    doc = re.sub('<[^<]+>', '', gp['document'])\n",
    "    doc_id = gp['doc_id']\n",
    "    \n",
    "    gold_canonical = convert_to_canonical(parse_convert(gold, gp['order_mapping']), True)\n",
    "    pred_canonical = convert_to_canonical(parse_convert(pred, gp['order_mapping']), False)\n",
    "    \n",
    "    text = f'**Document** ({doc_id})\\n\\n```\\n{doc}\\n```\\n\\n'\n",
    "    text += f'**Gold**\\n\\n```xml\\n{gold}\\n```\\n\\n'\n",
    "    text += f'**Pred**\\n\\n```xml\\n{pred}\\n```\\n\\n'\n",
    "    text += f'**Gold Canonical**\\n\\n```xml\\n{gold_canonical}\\n```\\n\\n'\n",
    "    text += f'**Pred Canonical**\\n\\n```xml\\n{pred_canonical}\\n```\\n\\n'\n",
    "    \n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_gp_pairs = []\n",
    "for gp in results['gold_pred_pairs']:\n",
    "    gold = gp['gold']\n",
    "    pred = gp['pred']\n",
    "    acc = gp['accuracy']\n",
    "    if acc < 1:\n",
    "        err_gp_pairs.append(gp)\n",
    "\n",
    "err_gp_pairs_it = iter(err_gp_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(err_gp_pairs_it)\n",
    "print_diff(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d31533",
   "metadata": {},
   "source": [
    "### Check Training Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6366d",
   "metadata": {},
   "source": [
    "This is to validate how many examples have the objective defined on a subset of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0877e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results, train_config, train_tokenizer = load_results(model_dir, TRAIN_RES_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11dcd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gp in train_results['gold_pred_pairs']:\n",
    "    gold = gp['gold']\n",
    "    gold_canonical = convert_to_canonical(parse_convert(gold, gp['order_mapping']), True)\n",
    "    \n",
    "    for obj_param in gold_canonical.objective:\n",
    "        if math.isclose(obj_param, 0):\n",
    "            print(f'Objective is defined on a subset of variables for {gp[\"doc_id\"]}. Objective: {gold_canonical.objective}')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b6d8b",
   "metadata": {},
   "source": [
    "### Check Constraint Directions of Correct Test Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d4510",
   "metadata": {},
   "source": [
    "The distribution of operators in the constraints of the correctly predicted test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8585c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results, test_config, test_tokenizer = load_results(model_dir, TEST_RES_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343498b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = parsers.ModelOutputXMLParser()\n",
    "const_type_dir_count = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "for gp in test_results['gold_pred_pairs']:\n",
    "    if not math.isclose(gp['accuracy'], 1):\n",
    "        continue\n",
    "        \n",
    "    gold = gp['gold']\n",
    "    xmltree = parser.xmltree(gold)\n",
    "    declarations = xmltree.iter('DECLARATION')\n",
    "    \n",
    "    for declaration in declarations:\n",
    "        if declaration.find('OBJ_DIR') is not None:\n",
    "            continue\n",
    "            \n",
    "        const_dir = declaration.find('OPERATOR')\n",
    "        const_type = declaration.find('CONST_TYPE')\n",
    "        const_type_dir_count[const_type.text.strip()][const_dir.text.strip()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(const_type_dir_count, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f017a",
   "metadata": {},
   "source": [
    "The distribution of operators for different constraint type in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train.jsonl') as f:\n",
    "    train_examples = [json.loads(l) for l in f]\n",
    "    \n",
    "\n",
    "const_type_dir_count = defaultdict(lambda : defaultdict(int))\n",
    "\n",
    "for example in train_examples:\n",
    "    assert len(example.values()) == 1\n",
    "    example = next(iter(example.values()))\n",
    "    for declr in example['const_declarations']:\n",
    "        const_type_dir_count[declr['type']][declr['operator']] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c079d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(const_type_dir_count, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20486c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
